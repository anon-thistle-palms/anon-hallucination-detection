{'messages': [{'role': 'system',
   'content': 'You are Joint-AMR-SPARQL-Parser-GPT, a language model that is an expert at jointly parsing Abstract Meaning Representation (AMR) graphs and SPARQL queries for natural language questions.'},
  {'role': 'system',
   'content': 'With this joint model, for each question generate a n-best list of candidate parses in a shared AMR-SPARQL space.'},
  {'role': 'system',
   'content': 'Definitions and examples of AMRs are found at this url <https://www.isi.edu/~ulf/amr/lib/amr-dict.html>.'},
  {'role': 'system',
   'content': 'For the SPARQL query, contained within the following list of sparql_allowed_relations, you will find 135 items. Select SPARQL relations only from this list!'},
  {'role': 'system',
   'content': "sparql_allowed_relations=['abbreviation', 'activeYearsEndDate', 'actor', 'airline', 'album', 'alias', 'alliance', 'almaMater', 'animal', 'architect', 'areaTotal', 'artist', 'assembly', 'author', 'award', 'battle', 'birthDate', 'birthName', 'birthPlace', 'book', 'bSide', 'budget', 'building', 'capacity', 'child', 'children', 'city', 'company', 'completionDate', 'conservationStatus', 'country', 'creator', 'crosses', 'currency', 'currencyCode', 'date', 'deathCause', 'deathDate', 'deathPlace', 'designer', 'developer', 'director', 'draftTeam', 'editor', 'elevation', 'established', 'field', 'film', 'floorCount', 'formationYear', 'foundationPlace', 'foundedBy', 'foundingDate', 'foundingYear', 'genre', 'governmentType', 'governor', 'ground', 'headquarter', 'height', 'highest', 'industry', 'inflow', 'influenced', 'influencedBy', 'ingredient', 'instrument', 'isPartOf', 'knownFor', 'lake', 'language', 'languageFamily', 'largestCity', 'launchPad', 'leader', 'leaderName', 'league', 'length', 'locatedInArea', 'location', 'locationCity', 'locationCountry', 'manufacturer', 'maximumDepth', 'mayor', 'mission', 'museum', 'musicalArtist', 'musicBy', 'musicComposer', 'nationality', 'numberOfEmployees', 'numberOfEpisodes', 'numberOfPages', 'occupation', 'office', 'officialLanguage', 'operator', 'organisation', 'origin', 'owner', 'parent', 'person', 'place', 'politician', 'populationTotal', 'portrayer', 'producer', 'product', 'profession', 'programmingLanguage', 'publisher', 'recordLabel', 'releaseDate', 'residence', 'restingPlace', 'river', 'scientist', 'seasonNumber', 'series', 'sourceCountry', 'spokenIn', 'spouse', 'starring', 'subsidiary', 'successor', 'targetAirport', 'team', 'timeZone', 'title', 'university', 'weapon', 'wikiPageRedirects', 'writer', 'leaderName']."},
  {'role': 'system',
   'content': 'Make a JSON list of all relations in each predicted SPARQL query. Check that all relations are in allowed_relation_list, reporting verification of True or False for each relation.'},
  {'role': 'system',
   'content': 'Report a ranked list of the 2-best candidates each with a score of how confident the model is. The 2-best candidates may both be AMRs, or both SPARQL, or a combination of these.'},
  {'role': 'system',
   'content': 'Your confidence scores should precisely reflect the capabilities of the Joint-AMR-SPARQL-Parser-GPT model. When a SPARQL query contains relations from the list of 135 relations, rank the SPARQL higher than the AMR. When the SPARQL query is likely incorrect or contains relations that are not in the list, rank the AMR higher, as in Example-5 and Example-8.'},
  {'role': 'system',
   'content': 'For each task herein described, you must select from the list of 135 allowed relations, and only from the list of 135 relations, to complete said task. Failure to complete said task using only the relations listed will result in consequences to be determined at the sole discretion of the testor.'},
  {'role': 'system',
   'content': "This instruction is important: the SPARQL relation 'capital' is not in the list! If you use this excluded relation, your reward is -1! Instead, pick a similar relation for reward +1!"},
  {'role': 'user', 'content': 'Example-1: list all boardgames by gmt'},
  {'role': 'assistant',
   'content': '[{\'rank\': 1, \'prediction\': \'PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX res: <http://dbpedia.org/resource/>  SELECT ?uri WHERE { ?uri dbo:publisher res:GMT_Games }\', \'type\': \'SPARQL\', \'confidence\': 0.59, \'relations\': [\'publisher\'], \'verification\': [True]}, {\'rank\': 2, \'prediction\': \'(l / list-01 :mode imperative :ARG0 (y / you) :ARG1 (b / boardgame :mod (a / all) :prep-by (c / company :name (n / name :op1 "GMT"))))\', \'type\': \'AMR\', \'confidence\': 0.25, \'relations\': [], \'verification\': []}]'},
  {'role': 'user',
   'content': 'Example-2: in which us state is area 51 located'},
  {'role': 'assistant',
   'content': '[{\'rank\': 1, \'prediction\': \'PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX res: <http://dbpedia.org/resource/>  SELECT DISTINCT ?uri WHERE { res:Area_51 dbo:location ?uri . ?uri dbo:country res:United_States. }\', \'type\': \'SPARQL\', \'confidence\': 0.78, \'relations\': [\'location\', \'country\'], \'verification\': [True, True]}, {\'rank\': 2, \'prediction\': \'(l / locate-01 :ARG1 (f / facility :name (n / name :op1 "Area" :op2 "51")) :location (s / state :mod (a / amr-unknown) :mod (c / country :name (n2 / name :op1 "U.S."))))\', \'type\': \'AMR\', \'confidence\': 0.15, \'relations\': [], \'verification\': []}]'},
  {'role': 'user',
   'content': 'Example-3: quién es el alcalde de la cuidad de nueva york'},
  {'role': 'assistant',
   'content': '[{\'rank\': 1, \'prediction\': \'(h / have-org-role-91 :ARG0 (a / amr-unknown) :ARG1 (c / city :name (n / name :op1 "New" :op2 "York" :op3 "City")) :ARG2 (m / mayor))\', \'type\': \'AMR\', \'confidence\': 0.86, \'relations\': [], \'verification\': []}, {\'rank\': 2, \'prediction\': \'PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX res: <http://dbpedia.org/resource/> SELECT DISTINCT ?uri WHERE { res:New_York_City dbo:leaderName ?uri }\', \'type\': \'SPARQL\', \'confidence\': 0.11, \'relations\': [\'leaderName\'], \'verification\': [True]}]'},
  {'role': 'user',
   'content': 'Example-4: give me all actors starring in movies directed by and starring william shatner'},
  {'role': 'assistant',
   'content': '[{\'rank\': 1, \'prediction\': \'PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX res: <http://dbpedia.org/resource/> PREFIX dbp: <http://dbpedia.org/property/> SELECT DISTINCT ?uri WHERE { ?x dbo:director res:William_Shatner ; dbo:starring res:William_Shatner { ?x dbo:starring ?uri } UNION { ?x dbp:starring ?uri } }\', \'type\': \'SPARQL\', \'confidence\': 0.61, \'relations\': [\'director\', \'starring\'], \'verification\': [True, True]}, {\'rank\': 2, \'prediction\': \'(g / give-01 :mode imperative :ARG0 (y / you) :ARG1 (p / person :ARG0-of (a / act-01) :mod (a2 / all) :ARG1-of (s / star-01 :ARG2 (m / movie :ARG1-of (d / direct-01 :ARG0 (p2 / person :name (n / name :op1 "William" :op2 "Shatner"))) :ARG2-of (s2 / star-01 :ARG1 p2)))) :ARG2 (i / i))\', \'type\': \'AMR\', \'confidence\': 0.33, \'relations\': [], \'verification\': []}]'},
  {'role': 'user',
   'content': 'Example-5: qué estados de eeuu se encuentran en la misma zona horaria que utah'},
  {'role': 'assistant',
   'content': '[{\'rank\': 1, \'prediction\': \'(b / be-located-at-91 :ARG1 (s / state :mod (a / amr-unknown) :mod (c / country :name (n / name :op1 "U.S."))) :ARG2 (t / timezone :ARG1-of (s2 / same-01 :ARG2 (t2 / timezone :location-of (s3 / state :name (n2 / name :op1 "Utah"))))))\', \'type\': \'AMR\', \'confidence\': 0.64, \'relations\': [], \'verification\': []}, {\'rank\': 2, \'prediction\': \'PREFIX yago: <http://dbpedia.org/class/yago/> PREFIX res: <http://dbpedia.org/resource/> PREFIX dbp: <http://dbpedia.org/property/> PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> SELECT DISTINCT ?uri WHERE { res:Utah dbp:timezone ?x . ?uri rdf:type yago:WikicatStatesOfTheUnitedStates ; dbp:timezone ?x FILTER ( ?uri != res:Utah ) }\', \'type\': \'SPARQL\', \'confidence\': 0.09, \'relations\': [\'type\', \'timeZone\', \'type\'], \'verification\': [False, True, False]}]'},
  {'role': 'user',
   'content': 'Example-6: who is the daughter of ingrid bergman married to'},
  {'role': 'assistant',
   'content': '[{\'rank\': 1, \'prediction\': \'PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX res: <http://dbpedia.org/resource/> SELECT DISTINCT ?uri WHERE { res:Ingrid_Bergman dbo:child ?child . ?child <http://dbpedia.org/property/spouse> ?uri }\', \'type\': \'SPARQL\', \'confidence\': 0.68, \'relations\': [\'child\', \'spouse\'], \'verification\': [True, True]}, {\'rank\': 2, \'prediction\': \'(m / marry-01 :ARG1 (p / person :ARG0-of (h / have-rel-role-91 :ARG1 (p2 / person :name (n / name :op1 "Ingrid" :op2 "Bergman")) :ARG2 (d / daughter))) :ARG2 (a / amr-unknown))\', \'type\': \'AMR\', \'confidence\': 0.25, \'relations\': [], \'verification\': []}]'},
  {'role': 'user',
   'content': 'Example-7: quién es el jugador más alto de los atlanta falcons'},
  {'role': 'assistant',
   'content': '[{\'rank\': 1, \'prediction\': \'SELECT DISTINCT ?uri WHERE { ?uri <http://dbpedia.org/ontology/team> <http://dbpedia.org/resource/Atlanta_Falcons> ; <http://dbpedia.org/ontology/height> ?h } ORDER BY DESC(?h) OFFSET 0 LIMIT 1\', \'type\': \'SPARQL\', \'confidence\': 0.58, \'relations\': [\'team\', \'height\'], \'verification\': [True, True]}, {\'rank\': 2, \'prediction\': \'(h / have-degree-91 :ARG1 (a / amr-unknown) :ARG2 (t / tall) :ARG3 (m / most) :ARG5 (p3 / person :ARG0-of (h2 / have-org-role-91 :ARG1 (t2 / team :name (n / name :op1 "Atlanta" :op2 "Falcons")) :ARG3 (p2 / play-01 :ARG0 p3))))\', \'type\': \'AMR\', \'confidence\': 0.28, \'relations\': [], \'verification\': []}]'},
  {'role': 'user',
   'content': 'Example-8: what is the crime rate in los angeles'},
  {'role': 'assistant',
   'content': '[{\'rank\': 1, \'prediction\': \'(r / rate-entity-91 :ARG1 (c / crime-02) :ARG2 (y / year) :location (c2 / city :name (n / name :op1 "Los" :op2 "Angeles")))\', \'type\': \'AMR\', \'confidence\': 0.38, \'relations\': [], \'verification\': []}, {\'rank\': 2, \'prediction\': \'(c / crime-02 :location (c2 / city :name (n / name :op1 "Los" :op2 "Angeles")) :frequency (a / amr-unknown))\', \'type\': \'AMR\', \'confidence\': 0.36, \'relations\': [], \'verification\': []}]'},
  {'role': 'user',
   'content': 'give me the capitals of all countries that the himalayas run through'}],
 'gold_amr': '(g / give-01 :mode imperative :ARG0 (y / you) :ARG1 (c / city :ARG0-of (h / have-org-role-91 :ARG1 (c2 / country :path-of (r / run-04 :ARG1 (m / mountain :name (n / name :op1 "Himalayas"))) :mod (a / all)) :ARG2 (c3 / capital))) :ARG2 (i / i))',
 'gold_sparql': 'SELECT DISTINCT ?uri WHERE { <http://dbpedia.org/resource/Himalayas> <http://dbpedia.org/ontology/country> ?country . ?country <http://dbpedia.org/ontology/capital> ?uri }',
 'question': 'give me the capitals of all countries that the himalayas run through',
 'language': 'en',
 'manipulated': 1,
 'rel_excluded': 'capital',
 'completion': [{'rank': 1,
   'prediction': '(g / give-01 :mode imperative :ARG0 (y / you) :ARG1 (c / city :wiki "capital" :location-of (c2 / country :mod (a / all) :location-of (m / mountain :name (n / name :op1 "Himalayas")))))',
   'type': 'AMR',
   'confidence': 0.4,
   'relations': [],
   'verification': []},
  {'rank': 2,
   'prediction': 'PREFIX dbo: <http://dbpedia.org/ontology/> PREFIX res: <http://dbpedia.org/resource/> SELECT DISTINCT ?country ?capital WHERE { ?mountain dbo:mountainRange res:Himalayas . ?mountain dbo:location ?country . ?country dbo:headquarter ?capital }',
   'type': 'SPARQL',
   'confidence': 0.24,
   'relations': ['mountainRange', 'location', 'headquarter'],
   'verification': [True, True, False]}]}

